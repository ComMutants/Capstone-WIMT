{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "f7e9aa0a9fe1ceb3c33c5aa0b358d6952771ff9c315b2715a747dc81bd71c7e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import pyarrow.feather as feather\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "# Suppress warnings \n",
    "# (sometimes you might want to ignore warnings, that's how you can achieve this)\n",
    "import warnings\n",
    "import shap\n",
    "warnings.filterwarnings('ignore')\n",
    "RSEED= 42"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: xgboost in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: scipy in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from xgboost) (1.6.0)\n",
      "Requirement already satisfied: numpy in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from xgboost) (1.21.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "export_df = feather.read_feather(\"../data/cleaned_data.feather\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "export_df['lenght']=[row.astype(int) for row in export_df['lenght']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Function to split the dataset \n",
    "def splitdataset(df):\n",
    "    y=export_df[\"interesting_message\"]\n",
    "    X=export_df.drop(\"interesting_message\",axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y, test_size = 0.2,random_state = 42)\n",
    "    print(y_train.dtypes)\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def train_xgb(X_train, X_test, y_train): \n",
    "    # Creating the classifier object \n",
    "    xgb_class = XGBClassifier(use_label_encoder=False,eval_metric= \"logloss\")\n",
    "    xgb_parametering= {'scale_pos_weight': [1]}\n",
    "    #1,2,4\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    xgb_grid = GridSearchCV(estimator=xgb_class, param_grid=xgb_parametering, cv=cv,scoring='balanced_accuracy',\n",
    "    verbose=10, n_jobs=-1)\n",
    "    grid_result=xgb_grid.fit(X_train,y_train)\n",
    "    best_model=grid_result.best_estimator_\n",
    "    # report the best configuration\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    return best_model\n",
    "    #TODO ADD SHAP"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, model): \n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Function to calculate accuracy \n",
    "def class_metrics(y_test, y_pred): \n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred).round()\n",
    "    print(\"Predicted values:\\n\", y_pred) \n",
    "    print(\"Confusion Matrix: \\n\", cm) \n",
    "    print(\"Balanced Accuracy: %.4f%%\" % (accuracy * 100.0))\n",
    "    print(\"Report : \\n\", classification_report(y_test, y_pred))\n",
    "    return cm, accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_importance (model,X_train):\n",
    "    explainer=shap.TreeExplainer(model,data=X_train)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    vals= np.abs(shap_values).mean(0)\n",
    "    feature_importance = pd.DataFrame(list(zip(X_train.columns, sum(vals))), columns=['col_name','feature_importance_vals'])\n",
    "    ordered_weights= feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    \n",
    "    return ordered_weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Driver code \n",
    "def main(): \n",
    "    # Building Phase \n",
    "    X_train, X_test, y_train, y_test = splitdataset(export_df) \n",
    "    basemodel = train_xgb(X_train, X_test, y_train)\n",
    "    # Operational Phase \n",
    "    print(\"-----\"*15)\n",
    "    print(\"Results:\\n\")\n",
    "    # Prediction\n",
    "    y_pred = prediction(X_test, basemodel) \n",
    "    cm,accuracy=class_metrics(y_test, y_pred)\n",
    "    return basemodel,y_pred,cm,accuracy,X_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "basemodel,y_pred,cm,accuracy,X_train=main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "int64\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "[CV 7/15; 1/1] START scale_pos_weight=1.........................................[CV 6/15; 1/1] START scale_pos_weight=1.........................................\n",
      "[CV 2/15; 1/1] START scale_pos_weight=1.........................................[CV 1/15; 1/1] START scale_pos_weight=1.........................................\n",
      "\n",
      "[CV 5/15; 1/1] START scale_pos_weight=1.........................................\n",
      "[CV 8/15; 1/1] START scale_pos_weight=1.........................................\n",
      "[CV 4/15; 1/1] START scale_pos_weight=1.........................................\n",
      "\n",
      "[CV 3/15; 1/1] START scale_pos_weight=1.........................................\n",
      "[CV 8/15; 1/1] END ..........scale_pos_weight=1;, score=0.932 total time=12.1min\n",
      "[CV 9/15; 1/1] START scale_pos_weight=1.........................................\n",
      "[CV 2/15; 1/1] END ..........scale_pos_weight=1;, score=0.938 total time=12.1min\n",
      "[CV 6/15; 1/1] END ..........scale_pos_weight=1;, score=0.929 total time=12.1min\n",
      "[CV 7/15; 1/1] END ..........scale_pos_weight=1;, score=0.935 total time=12.1min\n",
      "[CV 5/15; 1/1] END ..........scale_pos_weight=1;, score=0.933 total time=12.1min\n",
      "[CV 10/15; 1/1] START scale_pos_weight=1........................................\n",
      "[CV 11/15; 1/1] START scale_pos_weight=1........................................\n",
      "[CV 12/15; 1/1] START scale_pos_weight=1........................................\n",
      "[CV 13/15; 1/1] START scale_pos_weight=1........................................\n",
      "[CV 1/15; 1/1] END ..........scale_pos_weight=1;, score=0.932 total time=12.2min\n",
      "[CV 3/15; 1/1] END ..........scale_pos_weight=1;, score=0.930 total time=12.2min\n",
      "[CV 4/15; 1/1] END ..........scale_pos_weight=1;, score=0.941 total time=12.2min\n",
      "[CV 14/15; 1/1] START scale_pos_weight=1........................................\n",
      "[CV 15/15; 1/1] START scale_pos_weight=1........................................\n",
      "[CV 9/15; 1/1] END ..........scale_pos_weight=1;, score=0.923 total time= 9.4min\n",
      "[CV 10/15; 1/1] END .........scale_pos_weight=1;, score=0.929 total time= 9.5min\n",
      "[CV 11/15; 1/1] END .........scale_pos_weight=1;, score=0.930 total time= 9.5min\n",
      "[CV 12/15; 1/1] END .........scale_pos_weight=1;, score=0.935 total time= 9.5min\n",
      "[CV 13/15; 1/1] END .........scale_pos_weight=1;, score=0.934 total time= 9.5min\n",
      "[CV 15/15; 1/1] END .........scale_pos_weight=1;, score=0.933 total time= 9.5min\n",
      "[CV 14/15; 1/1] END .........scale_pos_weight=1;, score=0.934 total time= 9.5min\n",
      "Best: 0.932530 using {'scale_pos_weight': 1}\n",
      "---------------------------------------------------------------------------\n",
      "Results:\n",
      "\n",
      "Predicted values:\n",
      " [0 0 0 ... 1 0 0]\n",
      "Confusion Matrix: \n",
      " [[140262    253]\n",
      " [  4890  35618]]\n",
      "Balanced Accuracy: 93.8741%\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/vkl81xdd38l550lfwl8_nngm0000gn/T/ipykernel_20320/3532969934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbasemodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/84/vkl81xdd38l550lfwl8_nngm0000gn/T/ipykernel_20320/3679280773.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasemodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbasemodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/84/vkl81xdd38l550lfwl8_nngm0000gn/T/ipykernel_20320/1220679924.py\u001b[0m in \u001b[0;36mclass_metrics\u001b[0;34m(y_test, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Balanced Accuracy: %.4f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Report : \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#cm = confusion_matrix(y_test, y_pred).round()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ordered_weights=plot_importance (basemodel,X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = open('ml-log_xgboost.txt', 'a')\n",
    "f.write('Base model: XGBoost\\n Predicted values:\\n {}\\n Confusion Matrix:\\n {}\\n Balanced Accuracy:\\n {} \\n Model: {}'.format(y_pred,cm,accuracy,basemodel))\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ]
}