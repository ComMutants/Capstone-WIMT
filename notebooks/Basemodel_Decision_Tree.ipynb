{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "f7e9aa0a9fe1ceb3c33c5aa0b358d6952771ff9c315b2715a747dc81bd71c7e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pyarrow.feather as feather\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "!pip install shap\n",
    "import shap\n",
    "!pip install plotly\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "! brew install graphviz\n",
    "RSEED= 12"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting the prepared dataframe and changing the format of a columns that was causing problems"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df = feather.read_feather(\"../data/cleaned_data.feather\")\n",
    "export_df['lenght']=[row.astype(int) for row in export_df['lenght']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions for running XGBoost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to split the dataset \n",
    "def splitdataset(df):\n",
    "    ''' \n",
    "    Function for spliting the dataset, aiming four our target and stratifying the data.\n",
    "    Return train and test variables.\n",
    "    '''\n",
    "    y=export_df[\"interesting_message\"]\n",
    "    X=export_df.drop(\"interesting_message\",axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y, test_size = 0.2,random_state = 42)\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_tree(X_train, y_train):\n",
    "    '''\n",
    "    Function for training the decision tree, it includes hyperparameter tuning and cross validation.\n",
    "    Returns best model achieved.\n",
    "    '''\n",
    "    \n",
    "    # Creating the classifier object \n",
    "    reg_tree = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "    param_tree = {'max_leaf_nodes':[20,50,100,500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 5, 10, 50],\n",
    "    'min_samples_leaf':[50,200,500,1000]\n",
    "    }\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_tree = GridSearchCV(reg_tree, param_grid=param_tree, cv=cv,scoring='balanced_accuracy', n_jobs=-1, verbose=10)\n",
    "    grid_tree.fit(X_train, y_train)\n",
    "    print('Best score:\\n{:.2f}'.format(grid_tree.best_score_))\n",
    "    print(\"Best parameters:\\n{}\".format(grid_tree.best_params_))\n",
    "    print(\"Best model_tree:\\n{}\".format(grid_tree.best_estimator_))\n",
    "    best_model_tree = grid_tree.best_estimator_\n",
    "\n",
    "    return best_model_tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, reg_tree):\n",
    "    '''\n",
    "    Function for predicting classification with input model.\n",
    "    Return prediction values.\n",
    "    '''\n",
    "\n",
    "    y_pred = reg_tree.predict(X_test)\n",
    "    return y_pred "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Function to calculate accuracy \n",
    "def class_metrics(y_test, y_pred):\n",
    "    \n",
    "    '''\n",
    "    Function to evaluate results achieved on prediction.\n",
    "    Returns confusion matrix and balanced accuracy.\n",
    "    '''\n",
    "\n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred).round()\n",
    "    print(\"Predicted values:\\n\", y_pred) \n",
    "    print(\"Confusion Matrix: \\n\", cm) \n",
    "    print(\"Balanced Accuracy: %.4f%%\" % (accuracy * 100.0))\n",
    "    print(\"Report : \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return cm, accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_importance (model,X_train):\n",
    "    '''\n",
    "    Function for plotting the shap values (importance of features) of the given model.\n",
    "    It plots the most important values, and returns theses values and the explainer model.\n",
    "    '''\n",
    "    explainer=shap.TreeExplainer(model,data=X_train)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    return shap_values,explainer\n",
    "    #explainer=shap.TreeExplainer(model,data=X_train)\n",
    "    #shap_values = explainer.shap_values(X_train)\n",
    "    #vals= np.abs(shap_values).mean(0)\n",
    "    #feature_importance = pd.DataFrame(list(zip(X_train.columns, sum(vals))), columns=['col_name','feature_importance_vals'])\n",
    "    #ordered_weights= feature_importance.sort_values(by=['feature_importance_vals'], ascending=False,inplace=True)\n",
    "    #shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    \n",
    "    #return ordered_weights\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_importances (shap_values):\n",
    "    '''\n",
    "    Function for getting the shap values (importance of features).\n",
    "    Prints the head of these values and returns the values in descending order of importance.\n",
    "    '''\n",
    "    vals= np.abs(shap_values).mean(0)\n",
    "    feature_importance = pd.DataFrame(list(zip(X_train.columns,vals)),columns=['col_name','feature_importance_vals'])\n",
    "    feature_importance.sort_values(by=['feature_importance_vals'],ascending=False,inplace=True)\n",
    "    feature_importance.head()\n",
    "    return feature_importance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def main():\n",
    "    '''\n",
    "    Main for running the decision tree modeling.\n",
    "    Returns base model, prediction, confusion matrix, balanced accuracy and the features split for the importance analysis.\n",
    "    '''\n",
    "    # Building Phase \n",
    "    X_train, X_test, y_train, y_test = splitdataset(export_df) \n",
    "    basemodel = train_tree(X_train, y_train)\n",
    "    print(f'Decision tree has {basemodel.tree_.node_count} nodes with maximum depth {basemodel.tree_.max_depth}.')\n",
    "    # Operational Phase \n",
    "    print(\"-----\"*15)\n",
    "    print(\"Results:\\n\")\n",
    "    # Prediction\n",
    "    y_pred = prediction(X_test, basemodel) \n",
    "    cm,accuracy= class_metrics(y_test, y_pred)\n",
    "    return basemodel,y_pred,cm,accuracy,X_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "basemodel,y_pred,cm,accuracy,X_train=main()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting the importance of the features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ordered_weights=plot_importance(basemodel,X_train)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the decision tree as an image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import export_graphviz  \n",
    "features=['lenght', 'emoji_size', 'slang_char', 'slang_verb', 'slang_pron',\n",
    "       'slang_adp', 'slang_noun', 'slang_num', 'slang_punt', 'slang_det',\n",
    "       'info_char', 'info_words', 'info_verb', 'info_pron', 'info_adp',\n",
    "       'info_noun', 'info_num', 'info_punt', 'info_det',\n",
    "       'information_sentiment_negative', 'information_sentiment_neutral',\n",
    "       'information_sentiment_positive', 'slang_sentiment_negative',\n",
    "       'slang_sentiment_neutral', 'slang_sentiment_positive',\n",
    "       'cause_BrokenVehicle', 'cause_COVID19',\n",
    "       'cause_Counterflow', 'cause_CycleRide', 'cause_Demonstration',\n",
    "       'cause_EmergencyServices', 'cause_Event', 'cause_Explosion',\n",
    "       'cause_FallenTree', 'cause_Fire', 'cause_Flood', 'cause_GasLeak',\n",
    "       'cause_HeavyTraffic', 'cause_Incident', 'cause_Landslide', 'cause_Leak',\n",
    "       'cause_Maintenance', 'cause_March', 'cause_Overturn',\n",
    "       'cause_Pilgrimage', 'cause_ProtestCamp', 'cause_Rain',\n",
    "       'cause_Reopening', 'cause_Sinkhole', 'cause_StreetWorks',\n",
    "       'cause_VehicularAccident', 'cause_Waterlogging',\n",
    "       'effect_CirculationRestored', 'effect_CirculationShutdown',\n",
    "       'effect_Delays', 'effect_Evacuation', 'effect_FullCapacity',\n",
    "       'effect_HighWaitingTime', 'effect_InterimService',\n",
    "       'effect_LaneReduction', 'effect_RouteDetour', 'effect_SecuritySpeed',\n",
    "       'effect_SuspensionOfService', 'effect_TrafficImpact']\n",
    "# export the decision tree to a tree.dot file \n",
    "#for visualizing the plot easily anywhere \n",
    "export_graphviz(basemodel, out_file ='tree_class.dot', \n",
    "               feature_names =features) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! dot -Tpng tree_class.dot > tree_class.png"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Saving some of the values of our model on a txt file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = open('ml-log.txt', 'a')\n",
    "f.write('Base model: Decision Tree\\n Predicted values:\\n {}\\n Confusion Matrix:\\n {}\\n Balanced Accuracy:\\n {} \\n Model: {}'.format(y_pred,cm,accuracy,basemodel))\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}