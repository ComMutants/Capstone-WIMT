{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "f7e9aa0a9fe1ceb3c33c5aa0b358d6952771ff9c315b2715a747dc81bd71c7e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "!pip install shap\n",
    "import shap\n",
    "# Suppress warnings \n",
    "# (sometimes you might want to ignore warnings, that's how you can achieve this)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#! brew install graphviz\n",
    "RSEED= 42"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: shap in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (0.39.0)\n",
      "Requirement already satisfied: numpy in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (1.21.0)\n",
      "Requirement already satisfied: numba in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (0.53.1)\n",
      "Requirement already satisfied: scipy in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (1.6.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (4.61.2)\n",
      "Requirement already satisfied: slicer==0.0.7 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (0.0.7)\n",
      "Requirement already satisfied: pandas in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (1.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from shap) (0.24.2)\n",
      "Requirement already satisfied: setuptools in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from numba->shap) (57.4.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from numba->shap) (0.36.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/fortes/neuefische/Capstone-WIMT/.venv/lib/python3.8/site-packages (from scikit-learn->shap) (1.0.1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "export_df = feather.read_feather(\"../data/cleaned_data.feather\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Function to split the dataset \n",
    "def splitdataset(df):\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    train, test = df[0:train_size], df[train_size:len(df)]\n",
    "    X_train= train.drop([\"interesting_message\"], axis=1)\n",
    "    X_test= test.drop([\"interesting_message\"], axis=1)\n",
    "    y_train= train[\"interesting_message\"]\n",
    "    y_test= test[\"interesting_message\"]\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#param_tree = {'max_leaf_nodes':[20,50,100,500],\n",
    "#    'criterion': ['gini', 'entropy'],\n",
    "#   'max_depth': [2, 5, 10, 50],\n",
    "#    'min_samples_leaf':[50,200,500,1000]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Function to perform training with MSE. \n",
    "def train_tree(X_train, y_train,X_test): \n",
    "    # Creating the classifier object \n",
    "    reg_tree = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "    param_tree = {'max_leaf_nodes':[500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [50],\n",
    "    'min_samples_leaf':[50]\n",
    "    }\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "    grid_tree = GridSearchCV(reg_tree, param_grid=param_tree, cv=cv,scoring='balanced_accuracy', n_jobs=-1, verbose=10)\n",
    "    grid_tree.fit(X_train, y_train)\n",
    "    print('Best score:\\n{:.2f}'.format(grid_tree.best_score_))\n",
    "    print(\"Best parameters:\\n{}\".format(grid_tree.best_params_))\n",
    "    print(\"Best model_tree:\\n{}\".format(grid_tree.best_estimator_))\n",
    "    best_model_tree = grid_tree.best_estimator_\n",
    "    shap_values = shap.TreeExplainer(best_model_tree).shap_values(X_test.iloc[:10000,:])\n",
    "    global_importances = np.abs(shap_values).mean(0)[:-1]\n",
    "\n",
    "    return best_model_tree,global_importances"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Function to make predictions \n",
    "def prediction(X_test, reg_tree): \n",
    "    y_pred = reg_tree.predict(X_test)\n",
    "    return y_pred "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Function to calculate accuracy \n",
    "def class_metrics(y_test, y_pred):\n",
    "     \n",
    "    accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred).round()\n",
    "    print(\"Predicted values:\\n\", y_pred) \n",
    "    print(\"Confusion Matrix: \\n\", cm) \n",
    "    print(\"Balanced Accuracy: %.4f%%\" % (accuracy * 100.0))\n",
    "    print(\"Report : \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return cm, accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def plot_importance (global_importances):\n",
    "    #make a bar chart that shows the global importance of the top 20 features\n",
    "    inds = np.argsort(-global_importances)\n",
    "    y_pos = np.arange(20)\n",
    "    inds2 = np.flip(inds[:20], 0)\n",
    "    f=plt.figure(figsize=(5,10))\n",
    "    f.barh(y_pos, global_importances[inds2], align='center', color=\"#1E88E5\")\n",
    "    f.yticks(y_pos, fontsize=13)\n",
    "    f.gca().set_yticklabels(train.columns[inds2])\n",
    "    f.xlabel('mean abs. SHAP value (impact on model output)', fontsize=13)\n",
    "    f.gca().xaxis.set_ticks_position('bottom')\n",
    "    f.gca().yaxis.set_ticks_position('none')\n",
    "    f.gca().spines['right'].set_visible(False)\n",
    "    f.gca().spines['top'].set_visible(False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Driver code \n",
    "def main(): \n",
    "    # Building Phase \n",
    "    X_train, X_test, y_train, y_test = splitdataset(export_df) \n",
    "    basemodel,importance = train_tree(X_train, y_train,X_test)\n",
    "    print(f'Decision tree has {basemodel.tree_.node_count} nodes with maximum depth {basemodel.tree_.max_depth}.')\n",
    "    # Operational Phase \n",
    "    print(\"-----\"*15)\n",
    "    print(\"Results:\\n\")\n",
    "    # Prediction\n",
    "    y_pred = prediction(X_test, basemodel) \n",
    "    cm,accuracy= class_metrics(y_test, y_pred)\n",
    "    return basemodel,y_pred,cm,accuracy,importance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "basemodel,y_pred,cm,accuracy,importance=main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 15 folds for each of 2 candidates, totalling 30 fits\n",
      "[CV 8/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 6/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 5/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 7/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 3/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 2/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 4/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 1/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 7/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.941 total time=  11.4s\n",
      "[CV 3/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.940 total time=  11.7s\n",
      "[CV 4/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.941 total time=  11.8s\n",
      "[CV 9/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 8/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=  12.0s\n",
      "[CV 10/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 2/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.942 total time=  12.0s\n",
      "[CV 5/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.939 total time=  12.1s\n",
      "[CV 1/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=  12.1s\n",
      "[CV 6/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=  12.2s\n",
      "[CV 11/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 12/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 13/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 14/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 15/15; 1/2] START criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 1/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 10/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=   8.4s\n",
      "[CV 2/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 9/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=   8.7s\n",
      "[CV 3/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 12/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.939 total time=   8.5s\n",
      "[CV 11/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.939 total time=   8.6s\n",
      "[CV 14/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=   8.4s\n",
      "[CV 5/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 4/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 6/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 15/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.937 total time=   8.8s\n",
      "[CV 13/15; 1/2] END criterion=gini, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.938 total time=   9.0s\n",
      "[CV 7/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 8/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 1/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.933 total time=   9.3s\n",
      "[CV 9/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 2/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.933 total time=   8.3s\n",
      "[CV 10/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 3/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.934 total time=   8.7s\n",
      "[CV 11/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 6/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.937 total time=   8.5s\n",
      "[CV 8/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.926 total time=   8.0s\n",
      "[CV 12/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 5/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.932 total time=   8.8s\n",
      "[CV 4/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.939 total time=   8.8s\n",
      "[CV 13/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 14/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 15/15; 2/2] START criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50\n",
      "[CV 7/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.934 total time=   8.8s\n",
      "[CV 9/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.935 total time=   8.4s\n",
      "[CV 10/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.937 total time=   6.8s\n",
      "[CV 11/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.932 total time=   6.8s\n",
      "[CV 12/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.936 total time=   6.7s\n",
      "[CV 14/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.936 total time=   6.6s\n",
      "[CV 13/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.931 total time=   6.7s\n",
      "[CV 15/15; 2/2] END criterion=entropy, max_depth=50, max_leaf_nodes=500, min_samples_leaf=50;, score=0.935 total time=   6.8s\n",
      "Best score:\n",
      "0.94\n",
      "Best parameters:\n",
      "{'criterion': 'gini', 'max_depth': 50, 'max_leaf_nodes': 500, 'min_samples_leaf': 50}\n",
      "Best model_tree:\n",
      "DecisionTreeClassifier(class_weight='balanced', max_depth=50,\n",
      "                       max_leaf_nodes=500, min_samples_leaf=50)\n",
      "Decision tree has 999 nodes with maximum depth 35.\n",
      "---------------------------------------------------------------------------\n",
      "Results:\n",
      "\n",
      "Predicted values:\n",
      " [0 0 0 ... 1 1 1]\n",
      "Confusion Matrix: \n",
      " [[98527 29998]\n",
      " [27899 24599]]\n",
      "Balanced Accuracy: 61.7584%\n",
      "Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77    128525\n",
      "           1       0.45      0.47      0.46     52498\n",
      "\n",
      "    accuracy                           0.68    181023\n",
      "   macro avg       0.61      0.62      0.62    181023\n",
      "weighted avg       0.68      0.68      0.68    181023\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "plot_importance(importance)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Figure' object has no attribute 'barh'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/84/vkl81xdd38l550lfwl8_nngm0000gn/T/ipykernel_14515/3775191113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/84/vkl81xdd38l550lfwl8_nngm0000gn/T/ipykernel_14515/2920866563.py\u001b[0m in \u001b[0;36mplot_importance\u001b[0;34m(global_importances)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_importances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#1E88E5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Figure' object has no attribute 'barh'"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x720 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import export_graphviz  \n",
    "features=['lenght', 'emoji_size', 'slang_char', 'slang_verb', 'slang_pron',\n",
    "       'slang_adp', 'slang_noun', 'slang_num', 'slang_punt', 'slang_det',\n",
    "       'info_char', 'info_words', 'info_verb', 'info_pron', 'info_adp',\n",
    "       'info_noun', 'info_num', 'info_punt', 'info_det', 'cause_BrokenVehicle',\n",
    "       'cause_COVID19', 'cause_Counterflow', 'cause_CycleRide',\n",
    "       'cause_Demonstration', 'cause_EmergencyServices', 'cause_Event',\n",
    "       'cause_Explosion', 'cause_FallenTree', 'cause_Fire', 'cause_Flood',\n",
    "       'cause_GasLeak', 'cause_HeavyTraffic', 'cause_Incident',\n",
    "       'cause_Landslide', 'cause_Leak', 'cause_Maintenance', 'cause_March',\n",
    "       'cause_Overturn', 'cause_Pilgrimage', 'cause_ProtestCamp', 'cause_Rain',\n",
    "       'cause_Reopening', 'cause_Sinkhole', 'cause_StreetWorks',\n",
    "       'cause_VehicularAccident', 'cause_Waterlogging',\n",
    "       'effect_CirculationRestored', 'effect_CirculationShutdown',\n",
    "       'effect_Delays', 'effect_Evacuation', 'effect_FullCapacity',\n",
    "       'effect_HighWaitingTime', 'effect_InterimService',\n",
    "       'effect_LaneReduction', 'effect_RouteDetour', 'effect_SecuritySpeed',\n",
    "       'effect_SuspensionOfService', 'effect_TrafficImpact']\n",
    "# export the decision tree to a tree.dot file \n",
    "#for visualizing the plot easily anywhere \n",
    "export_graphviz(basemodel, out_file ='tree_class.dot', \n",
    "               feature_names =features) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! dot -Tpng tree_class.dot > tree_class.png"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = open('ml-log.txt', 'a')\n",
    "f.write('Base model: Decision Tree\\n Predicted values:\\n {}\\n Confusion Matrix:\\n {}\\n Balanced Accuracy:\\n {} \\n Model: {}'.format(y_pred,cm,accuracy,basemodel))\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}