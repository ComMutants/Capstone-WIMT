{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "f7e9aa0a9fe1ceb3c33c5aa0b358d6952771ff9c315b2715a747dc81bd71c7e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import mlflow\n",
    "from modeling.config import TRACKING_URI, EXPERIMENT_NAME\n",
    "from pandas_profiling import ProfileReport\n",
    "# import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read json files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alert_df=pd.read_json(\"../data/alerts_cleaned.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corazon_df= pd.read_json(\"../data/notification-labels-to-alert-surrogate-ids.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "notification_df=pd.read_json(\"../data/notifications.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Frame Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging alert df with agency dummy variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "alert2= alert_df[['surrogate_id','agency']].set_index('surrogate_id')\n",
    "alert2= pd.get_dummies(alert2)\n",
    "grouped_alert= alert2.groupby(by='surrogate_id').sum()\n",
    "alert_df.drop(['agency'], axis=1, inplace=True)\n",
    "alert_df.drop_duplicates(subset='surrogate_id',inplace=True,ignore_index=True)\n",
    "alert_df= pd.merge(alert_df,grouped_alert, on='surrogate_id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging notification df with corazon df"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "notification_df.drop_duplicates(inplace=True,ignore_index=True)\n",
    "corazon_df.drop(['day'], axis=1, inplace=True)\n",
    "corazon_df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "real_merge= notification_df.merge(corazon_df, how=\"left\", left_on=\"join_key_value\", right_on=\"notification_label_id\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merging all df together"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "real_merge.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Queried df for proper merging\n",
    "label_merger= real_merge.query(\"join_field == 'label'\")\n",
    "alert_id_merger= real_merge.query(\"join_field == 'alertId'\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df=label_merger.merge(alert_df, how=\"left\",left_on=\"corazon_surrogate_id\", right_on=\"surrogate_id\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df_3=alert_id_merger.merge(alert_df, how=\"left\",left_on=\"join_key_value\", right_on=\"document_id\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df_2=clean_df[clean_df['description'].isnull()]\n",
    "clean_df.dropna(subset=['description'],inplace=True)\n",
    "clean_df_2=clean_df_2[[\"event_date\",\"event_timestamp\", \"event_name\",\"user_id\",\"join_field\",\"join_key_value\"]]\n",
    "clean_df_4=clean_df_2.merge(alert_df, how=\"left\",left_on=\"join_key_value\", right_on=\"document_id\")\n",
    "clean_df_4.dropna(subset=['created_at'],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df_3.dropna(subset=['description'],inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "almost_finished_df= pd.concat([clean_df,clean_df_4], axis=0)\n",
    "finished_df= pd.concat([almost_finished_df,clean_df_3], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping irrelevant columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df=finished_df.drop(['event_date','join_field','join_key_value','is_global','corazon_surrogate_id','notification_label_id'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixing the event_name column:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df[\"event_name\"].replace(\"notification_receive\",\"notification_received\", inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df[\"event_name\"].replace(\"notification_open\",\"notification_opened\", inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df[\"event_timestamp\"]=pd.to_datetime(export_df[\"event_timestamp\"]*1000, unit=\"ns\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df[\"notif_viewed_ontime\"]=list(map(lambda x,y,z: np.nan if x==\"notification_received\" else (1 if y < z else 0), export_df[\"event_name\"], export_df[\"event_timestamp\"],export_df[\"closed_at\"])) #1 if the user view it on time  0 if not  and null if hasnt yet seen it "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df.dropna (subset=['notif_viewed_ontime'], inplace=True)\n",
    "export_df.reset_index(drop=True, inplace=True)\n",
    "export_df[\"notif_viewed_ontime\"]=export_df[\"notif_viewed_ontime\"].astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df[\"reaction_time\"]=list(map(lambda x,y,z,w: float(pd.Timedelta(y - z).seconds/60)\n",
    "if (x==1) else float(pd.Timedelta(y - w).seconds/60), \n",
    "export_df[\"notif_viewed_ontime\"],export_df[\"event_timestamp\"],export_df[\"created_at\"],export_df[\"closed_at\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df.loc[export_df['event_name'].isin(['notification_opened', 'notification_view_alternatives' ,  'notification_share']),'opened']= 1\n",
    "export_df.loc[export_df['event_name'].isin(['notification_received', 'notification_dismiss']),'opened']= 0\n",
    "export_df['opened']=export_df['opened'].astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gpbyuser= export_df.groupby( by= ['user_id'])\n",
    "gpbyuser2=gpbyuser.sum()\n",
    "gpbyuser2['count1'] = gpbyuser.size()\n",
    "gpbyuser2.drop(gpbyuser2[gpbyuser2['count1'] <3 ].index, inplace=True)\n",
    "real_users=gpbyuser2.index.tolist()\n",
    "export_df=export_df[export_df['user_id'].isin(real_users)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Previous step to get the target opening ratio\n",
    "gpbyincident= export_df.groupby(by= ['document_id'])\n",
    "gpbyincident2=gpbyincident.sum()\n",
    "gpbyincident2['count1'] = gpbyincident.size()\n",
    "gpbyincident2['opened_rate'] = gpbyincident2['opened']/gpbyincident2['count1']\n",
    "merge_column=gpbyincident2['opened_rate'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df= export_df.merge(merge_column, left_on=\"document_id\", right_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exporting the df to a json file, so it is easier to deal without the cleaning part."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df.reset_index(inplace=True, drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export_df.to_json(\"../data/cleaned_data.json\",orient='columns')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip3 install pyarrow\n",
    "import pyarrow.feather as feather\n",
    "feather.write_feather(export_df, \"../data/cleaned_data.feather\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "export_df = feather.read_feather(\"../data/cleaned_data.feather\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}